{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHk4N71j6oGP",
        "outputId": "347c68c9-d488-42a4-ffd2-afccb269fb48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from wordcloud import WordCloud\n",
        "from konlpy.tag import Okt\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "kphKo0Ap677C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "형태소분석기 = Okt()"
      ],
      "metadata": {
        "id": "NmbdyCUe683g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from gensim.models import FastText\n",
        "from gensim.utils import simple_preprocess\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# 형태소 분석기 초기화\n",
        "형태소분석기 = Okt()\n",
        "\n",
        "# 문장 리스트\n",
        "문장들 = [\n",
        "    '카페가 너무 많아',\n",
        "    '파스타 맛집이 생겼으면 좋겠다',\n",
        "    '광운대 주변에는 왜 맥도날드나 롯데리아 같은 패스트푸드점이 없는거야?',\n",
        "    '피자집 망했으면'\n",
        "]\n",
        "\n",
        "# 긍정 형용사, 부정 형용사, 긍정 부사, 부정 부사를 필터링할 키워드\n",
        "긍정_형용사_키워드 = ['좋', '사랑', '기대', '행복', '정말']\n",
        "부정_형용사_키워드 = ['싫', '별로', '왜', '없', '너무', '망']\n",
        "긍정_부사_키워드 = 긍정_형용사_키워드  # 부사의 긍정적 키워드\n",
        "부정_부사_키워드 = 부정_형용사_키워드  # 부사의 부정적 키워드\n",
        "\n",
        "# 의미 없는 단어 필터링을 위한 집합\n",
        "의미없는_단어 = {'은', '이', '가', '에', '의', '를', '와', '과', '도', '로', '서', '에서'}\n",
        "\n",
        "# 단어 토큰화\n",
        "토큰화된_문서들 = [simple_preprocess(문장) for 문장 in 문장들]\n",
        "\n",
        "# FastText 모델 훈련\n",
        "모델 = FastText(토큰화된_문서들, vector_size=50, window=3, min_count=1)\n",
        "\n",
        "# 각 문장에서 가장 중요한 명사 단어를 찾기 위한 함수\n",
        "def 중요한_단어_추출(명사_리스트, 모델):\n",
        "    # 모델에 있는 단어만 필터링\n",
        "    명사_필터링_단어들 = [단어 for 단어 in 명사_리스트 if 단어 in 모델.wv.index_to_key]\n",
        "\n",
        "    if not 명사_필터링_단어들:\n",
        "        # 명사 리스트에서 첫 번째 단어를 반환 (빈 경우)\n",
        "        return 명사_리스트[0] if 명사_리스트 else None\n",
        "\n",
        "    # 각 명사 단어의 벡터를 평균내어 문장 벡터를 생성\n",
        "    벡터_값들 = [모델.wv.get_vector(단어) for 단어 in 명사_필터링_단어들]\n",
        "    평균_벡터 = np.mean(벡터_값들, axis=0)\n",
        "\n",
        "    # 명사 단어의 벡터와 평균 벡터의 유사도를 계산\n",
        "    유사도_점수 = {}\n",
        "    for 단어 in 명사_필터링_단어들:\n",
        "        단어_벡터 = 모델.wv.get_vector(단어)\n",
        "        유사도_점수[단어] = 1 - cosine(단어_벡터, 평균_벡터)\n",
        "\n",
        "    # 가장 높은 유사도 점수를 가진 단어를 선택\n",
        "    if 유사도_점수:\n",
        "        가장_중요한_단어 = max(유사도_점수, key=유사도_점수.get)\n",
        "        return 가장_중요한_단어\n",
        "    else:\n",
        "        # 명사 리스트에서 첫 번째 단어를 반환 (빈 경우)\n",
        "        return 명사_리스트[0] if 명사_리스트 else None\n",
        "\n",
        "# 문장별로 분석 및 결과 출력\n",
        "for i, 문장 in enumerate(문장들):\n",
        "    # 필터링된 결과 저장할 리스트 초기화\n",
        "    명사 = []\n",
        "    동사 = []\n",
        "    긍정_형용사 = []\n",
        "    부정_형용사 = []\n",
        "    긍정_부사 = []\n",
        "    부정_부사 = []\n",
        "\n",
        "    # 각 문장에 대해 분석\n",
        "    분석결과 = 형태소분석기.pos(문장)\n",
        "\n",
        "    # 형태소 분석 결과의 단어와 품사 조정\n",
        "    임시_단어 = []\n",
        "    for 단어, 품사 in 분석결과:\n",
        "        if 단어 in 의미없는_단어:\n",
        "            continue\n",
        "\n",
        "        # `별로`를 부정 부사로 강제로 분류\n",
        "        if 단어 == '별로':\n",
        "            부정_부사.append((단어, '부정 부사'))\n",
        "        else:\n",
        "            # 단어가 음절 단위로 나뉘는 경우를 처리\n",
        "            if 품사 in ['Noun', 'Verb', 'Adjective', 'Adverb']:\n",
        "                임시_단어.append((단어, 품사))\n",
        "\n",
        "    # 필요한 품사 필터링\n",
        "    for 단어, 품사 in 임시_단어:\n",
        "        if 품사 == 'Noun':  # 명사\n",
        "            명사.append(단어)\n",
        "\n",
        "        elif 품사 == 'Adjective':  # 형용사 (긍정/부정 형용사로 분류)\n",
        "            if any(keyword in 단어 for keyword in 긍정_형용사_키워드):\n",
        "                긍정_형용사.append((단어, '긍정 형용사'))\n",
        "            elif any(keyword in 단어 for keyword in 부정_형용사_키워드):\n",
        "                부정_형용사.append((단어, '부정 형용사'))\n",
        "\n",
        "        elif 품사 == 'Adverb':  # 부사 (긍정/부정 부사로 분류)\n",
        "            if any(keyword in 단어 for keyword in 긍정_부사_키워드):\n",
        "                긍정_부사.append((단어, '긍정 부사'))\n",
        "            elif any(keyword in 단어 for keyword in 부정_부사_키워드):\n",
        "                부정_부사.append((단어, '부정 부사'))\n",
        "\n",
        "        elif 품사 == 'Verb':  # 동사 (동사로 분류)\n",
        "            동사.append((단어, 품사))\n",
        "\n",
        "    # 긍정과 부정의 개수 세기\n",
        "    긍정_형용사_개수 = len(긍정_형용사)\n",
        "    부정_형용사_개수 = len(부정_형용사)\n",
        "    긍정_부사_개수 = len(긍정_부사)\n",
        "    부정_부사_개수 = len(부정_부사)\n",
        "\n",
        "    # 각 문장에서 가장 중요한 명사 추출\n",
        "    가장_중요한_단어 = 중요한_단어_추출(명사, 모델)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"{i+1} 번째 시도\")\n",
        "    print(\"명사:\", 명사)\n",
        "    print(\"동사:\", 동사)\n",
        "    print(\"긍정 형용사:\", 긍정_형용사)\n",
        "    print(\"부정 형용사:\", 부정_형용사)\n",
        "    print(\"긍정 부사:\", 긍정_부사)\n",
        "    print(\"부정 부사:\", 부정_부사)\n",
        "    print(f\"긍정 표현 개수: {긍정_형용사_개수 + 긍정_부사_개수}\")\n",
        "    print(f\"부정 표현 개수: {부정_형용사_개수 + 부정_부사_개수}\")\n",
        "    print(f\"가장 중요해 보이는 명사: {가장_중요한_단어}\")\n",
        "    print()  # 빈 줄 추가\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de2WJcOJ7Pw-",
        "outputId": "be22d6af-6085-4530-8d8a-b4b5355112ee"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 번째 시도\n",
            "명사: ['카페']\n",
            "동사: []\n",
            "긍정 형용사: []\n",
            "부정 형용사: []\n",
            "긍정 부사: []\n",
            "부정 부사: [('너무', '부정 부사')]\n",
            "긍정 표현 개수: 0\n",
            "부정 표현 개수: 1\n",
            "가장 중요해 보이는 명사: 카페\n",
            "\n",
            "2 번째 시도\n",
            "명사: ['파스타', '맛집']\n",
            "동사: [('생겼으면', 'Verb')]\n",
            "긍정 형용사: [('좋겠다', '긍정 형용사')]\n",
            "부정 형용사: []\n",
            "긍정 부사: []\n",
            "부정 부사: []\n",
            "긍정 표현 개수: 1\n",
            "부정 표현 개수: 0\n",
            "가장 중요해 보이는 명사: 파스타\n",
            "\n",
            "3 번째 시도\n",
            "명사: ['광운대', '주변', '왜', '맥도날드', '롯데리아', '패스트푸드', '점']\n",
            "동사: []\n",
            "긍정 형용사: []\n",
            "부정 형용사: [('없는거야', '부정 형용사')]\n",
            "긍정 부사: []\n",
            "부정 부사: []\n",
            "긍정 표현 개수: 0\n",
            "부정 표현 개수: 1\n",
            "가장 중요해 보이는 명사: 광운대\n",
            "\n",
            "4 번째 시도\n",
            "명사: ['피자', '집']\n",
            "동사: []\n",
            "긍정 형용사: []\n",
            "부정 형용사: [('망했으면', '부정 형용사')]\n",
            "긍정 부사: []\n",
            "부정 부사: []\n",
            "긍정 표현 개수: 0\n",
            "부정 표현 개수: 1\n",
            "가장 중요해 보이는 명사: 피자\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uFU0a7FTYaQC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}